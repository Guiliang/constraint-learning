{
    "task": "PPO-highD",
    "group": "PPO-highD",
    "device": "cuda",
    "verbose": 2,
    "seed": 3,
    "env": {
        "config_path": "../config/highD_environment_configurations.yaml",
        "train_env_id": "commonroad-v1",
        "eval_env_id": "commonroad-v1",
        "save_dir": "../save_model",
        "cost_info_str": "",
        "num_threads": 2,
        "use_cost": false,
        "reward_gamma": 0.99,
        "cost_gamma": "None",
        "dont_normalize_obs": false,
        "dont_normalize_reward": false,
        "dont_normalize_cost": true
    },
    "running": {
        "n_iters": 30000,
        "n_eval_episodes": 10,
        "save_every": 50
    },
    "PPO": {
        "policy_name": "MlpPolicy",
        "learning_rate": 0.0005,
        "n_steps": 1024,
        "n_epochs": 10,
        "clip_obs": 20,
        "reward_gamma": 0.99,
        "reward_gae_lambda": 0.95,
        "clip_range": 0.2,
        "ent_coef": 0.0,
        "reward_vf_coef": 0.5,
        "max_grad_norm": 0.5,
        "use_sde": false,
        "sde_sample_freq": -1,
        "target_kl": 0.01,
        "shared_layers": "None",
        "policy_layers": [
            64,
            64
        ],
        "reward_vf_layers": [
            64,
            64
        ],
        "cost_vf_layers": false,
        "batch_size": 64,
        "num_threads": 5,
        "eval_every": 2048,
        "use_curiosity_driven_exploration": false,
        "warmup_timesteps": false,
        "reset_policy": false,
        "forward_timesteps": 20000
    }
}
